from __future__ import annotations

import pandas as pd
import streamlit as st

from src.data_providers import fetch_price_history, symbol_with_name
from src.trade_log import load_signal_log, summarize_logs

st.title("ğŸ“’ Signal Log")
st.caption("ì €ì¥í•œ ì‹œê·¸ë„ ê¸°ë¡ê³¼ ì¶”ì  ì„±ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")

log_df = load_signal_log(limit=2000)
summary = summarize_logs(log_df)

k1, k2, k3, k4 = st.columns(4)
with k1:
    st.metric("ê¸°ë¡ ìˆ˜", summary["rows"])
with k2:
    st.metric("ì¶”ê°€ë§¤ìˆ˜ ê¸°ë¡", summary["buy_signals"])
with k3:
    st.metric("ë§¤ë„ ê¸°ë¡", summary["sell_signals"])
with k4:
    st.metric("í‰ê·  ì ìˆ˜", f"{summary['avg_score']:.1f}")

if log_df.empty:
    st.info("ì €ì¥ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. Analysis í˜ì´ì§€ì—ì„œ ì‹œê·¸ë„ì„ ê¸°ë¡í•˜ì„¸ìš”.")
    st.stop()

st.markdown("### ë¡œê·¸ í•„í„°")
f1, f2, f3, f4 = st.columns(4)
with f1:
    days_filter = st.selectbox("ê¸°ê°„", [7, 30, 90, 180, 365, 9999], index=2, format_func=lambda x: "ì „ì²´" if x == 9999 else f"ìµœê·¼ {x}ì¼")
with f2:
    market_filter = st.multiselect("ì‹œì¥", sorted(log_df["market"].dropna().astype(str).unique().tolist()), default=sorted(log_df["market"].dropna().astype(str).unique().tolist()))
with f3:
    profile_filter = st.multiselect("í”„ë¦¬ì…‹", sorted(log_df["profile"].dropna().astype(str).unique().tolist()), default=sorted(log_df["profile"].dropna().astype(str).unique().tolist()))
with f4:
    min_score = st.slider("ìµœì†Œ ì ìˆ˜", 0, 100, 0)

filtered_log = log_df.copy()
filtered_log["symbol_name"] = filtered_log.apply(
    lambda r: symbol_with_name(str(r.get("symbol", "")), str(r.get("market", "US"))),
    axis=1,
)
filtered_log["ts_dt"] = pd.to_datetime(filtered_log["ts"], errors="coerce")
if days_filter != 9999:
    cutoff = pd.Timestamp.now() - pd.Timedelta(days=days_filter)
    filtered_log = filtered_log[filtered_log["ts_dt"] >= cutoff]
if market_filter:
    filtered_log = filtered_log[filtered_log["market"].astype(str).isin(market_filter)]
if profile_filter:
    filtered_log = filtered_log[filtered_log["profile"].astype(str).isin(profile_filter)]
filtered_log = filtered_log[pd.to_numeric(filtered_log["score"], errors="coerce").fillna(0) >= min_score]

st.subheader("ê¸°ë¡ ëª©ë¡")
show_cols = [
    "ts",
    "symbol_name",
    "market",
    "profile",
    "action",
    "score",
    "confidence",
    "price",
    "stop",
    "tp1",
    "rr_tp1",
]
avail_cols = [c for c in show_cols if c in filtered_log.columns]
st.dataframe(filtered_log.sort_values("ts", ascending=False)[avail_cols], use_container_width=True, hide_index=True)

st.markdown("---")
st.subheader("ìµœê·¼ 50ê±´ ì¶”ì  ì„±ê³¼")

recent = filtered_log.sort_values("ts", ascending=False).head(50).copy()
apply_slippage = st.checkbox("ìŠ¬ë¦¬í”¼ì§€ ë°˜ì˜ ì„±ê³¼ ë³´ê¸°", value=True)
horizon_days = st.slider("ì‚¬í›„ ê²€ì¦ ê¸°ê°„(ì¼)", 3, 30, 10)
rows = []


@st.cache_data(ttl=600)
def _load_live_snapshot(symbol: str, market: str) -> tuple[float, float]:
    _, px_df = fetch_price_history(symbol, market, period="3mo", interval="1d")
    now_price = float(px_df.iloc[-1]["close"])
    volume_value = float(px_df.iloc[-1]["volume"]) * now_price
    return now_price, volume_value


@st.cache_data(ttl=600)
def _load_history(symbol: str, market: str) -> pd.DataFrame:
    _, px_df = fetch_price_history(symbol, market, period="2y", interval="1d")
    hist = px_df.copy()
    hist = hist.sort_index()
    hist["date"] = pd.to_datetime(hist.index).tz_localize(None).date
    return hist


def _slippage_bps(volume_value: float) -> float:
    # ìœ ë™ì„±ì— ë”°ë¥¸ ë‹¨ìˆœ ìŠ¬ë¦¬í”¼ì§€ ëª¨ë¸ (ì™•ë³µ)
    if volume_value >= 300_000_000:
        return 6.0
    if volume_value >= 100_000_000:
        return 10.0
    if volume_value >= 30_000_000:
        return 18.0
    if volume_value >= 10_000_000:
        return 28.0
    return 45.0


for _, row in recent.iterrows():
    symbol = str(row.get("symbol", "")).strip()
    market = str(row.get("market", "US")).strip()
    entry = float(pd.to_numeric(row.get("price", 0), errors="coerce") or 0)
    action = str(row.get("action", "ë³´ìœ "))

    if not symbol or entry <= 0:
        continue

    try:
        now_price, volume_value = _load_live_snapshot(symbol, market)

        if action == "ì¶”ê°€ë§¤ìˆ˜":
            ret = (now_price / entry - 1.0) * 100
        elif action == "ë§¤ë„":
            ret = (entry / now_price - 1.0) * 100 if now_price > 0 else 0.0
        else:
            ret = (now_price / entry - 1.0) * 100

        slip_bps = _slippage_bps(volume_value)
        slip_pct = slip_bps / 100.0
        ret_net = ret - slip_pct if apply_slippage else ret

        rows.append(
            {
                "ts": row.get("ts"),
                "symbol": symbol,
                "symbol_name": symbol_with_name(symbol, market),
                "profile": row.get("profile", ""),
                "market": market,
                "action": action,
                "entry": entry,
                "now": now_price,
                "volume_value": volume_value,
                "slippage_bps": slip_bps,
                "return_raw_pct": ret,
                "return_net_pct": ret_net,
            }
        )
    except Exception:
        continue

if rows:
    perf_df = pd.DataFrame(rows)
    st.dataframe(
        perf_df[
            [
                "ts",
                "symbol_name",
                "profile",
                "market",
                "action",
                "entry",
                "now",
                "volume_value",
                "slippage_bps",
                "return_raw_pct",
                "return_net_pct",
            ]
        ],
        use_container_width=True,
        hide_index=True,
    )

    p1, p2, p3 = st.columns(3)
    with p1:
        st.metric("ì¶”ì  ê±´ìˆ˜", len(perf_df))
    with p2:
        st.metric("í‰ê·  ìˆ˜ìµë¥ (ì›ì‹œ)", f"{perf_df['return_raw_pct'].mean():+.2f}%")
    with p3:
        st.metric("í‰ê·  ìˆ˜ìµë¥ (ìŠ¬ë¦½ë°˜ì˜)", f"{perf_df['return_net_pct'].mean():+.2f}%")

    p4, p5 = st.columns(2)
    with p4:
        win_rate_raw = (perf_df["return_raw_pct"] > 0).mean() * 100
        st.metric("ìŠ¹ë¥ (ì›ì‹œ)", f"{win_rate_raw:.1f}%")
    with p5:
        win_rate_net = (perf_df["return_net_pct"] > 0).mean() * 100
        st.metric("ìŠ¹ë¥ (ìŠ¬ë¦½ë°˜ì˜)", f"{win_rate_net:.1f}%")

    st.markdown("---")
    st.subheader("í”„ë¦¬ì…‹ë³„ ì„±ê³¼ ë¹„êµ")
    preset_df = (
        perf_df.groupby("profile", dropna=False)
        .agg(
            count=("symbol", "count"),
            avg_raw=("return_raw_pct", "mean"),
            avg_net=("return_net_pct", "mean"),
            win_raw=("return_raw_pct", lambda s: (s > 0).mean() * 100),
            win_net=("return_net_pct", lambda s: (s > 0).mean() * 100),
            avg_slip_bps=("slippage_bps", "mean"),
        )
        .reset_index()
        .sort_values("avg_net", ascending=False)
    )
    st.dataframe(preset_df, use_container_width=True, hide_index=True)
else:
    st.warning("ì¶”ì  ê°€ëŠ¥í•œ ìµœê·¼ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("---")
st.subheader("Nì¼ í›„ ì‹¤ì œ ì„±ê³¼ ë¼ë²¨ë§")
label_rows = []
label_source = filtered_log.sort_values("ts", ascending=False).head(200).copy()
for _, row in label_source.iterrows():
    symbol = str(row.get("symbol", "")).strip()
    market = str(row.get("market", "US")).strip()
    action = str(row.get("action", "ë³´ìœ "))
    ts = pd.to_datetime(row.get("ts"), errors="coerce")
    if not symbol or pd.isna(ts):
        continue

    try:
        hist = _load_history(symbol, market)
        if hist.empty:
            continue

        entry_date = ts.date()
        future_date = (ts + pd.Timedelta(days=horizon_days)).date()

        entry_rows = hist[hist["date"] >= entry_date]
        future_rows = hist[hist["date"] >= future_date]
        if entry_rows.empty or future_rows.empty:
            continue

        entry = float(entry_rows.iloc[0]["close"])
        future = float(future_rows.iloc[0]["close"])
        if entry <= 0 or future <= 0:
            continue

        if action == "ì¶”ê°€ë§¤ìˆ˜":
            fwd_ret = (future / entry - 1.0) * 100
            is_hit = fwd_ret > 0
        elif action == "ë§¤ë„":
            fwd_ret = (entry / future - 1.0) * 100
            is_hit = fwd_ret > 0
        else:
            fwd_ret = (future / entry - 1.0) * 100
            is_hit = abs(fwd_ret) <= 3

        label_rows.append(
            {
                "ts": row.get("ts"),
                "symbol": symbol,
                "symbol_name": symbol_with_name(symbol, market),
                "profile": row.get("profile", ""),
                "market": market,
                "action": action,
                f"fwd_{horizon_days}d_ret_pct": fwd_ret,
                "hit": "HIT" if is_hit else "MISS",
            }
        )
    except Exception:
        continue

if label_rows:
    label_df = pd.DataFrame(label_rows)
    label_cols = [
        "ts",
        "symbol_name",
        "market",
        "profile",
        "action",
        f"fwd_{horizon_days}d_ret_pct",
        "hit",
    ]
    st.dataframe(label_df[[c for c in label_cols if c in label_df.columns]], use_container_width=True, hide_index=True)

    l1, l2, l3 = st.columns(3)
    with l1:
        hit_rate = (label_df["hit"] == "HIT").mean() * 100
        st.metric("ë¼ë²¨ë§ ê±´ìˆ˜", len(label_df))
    with l2:
        st.metric("HIT ë¹„ìœ¨", f"{hit_rate:.1f}%")
    with l3:
        st.metric("í‰ê·  ì„ í–‰ ìˆ˜ìµ", f"{label_df[f'fwd_{horizon_days}d_ret_pct'].mean():+.2f}%")

    st.markdown("#### í”„ë¦¬ì…‹ë³„ ë¼ë²¨ë§ ì„±ê³¼")
    by_profile = (
        label_df.groupby("profile", dropna=False)
        .agg(
            count=("symbol", "count"),
            hit_rate=("hit", lambda s: (s == "HIT").mean() * 100),
            avg_fwd_ret=(f"fwd_{horizon_days}d_ret_pct", "mean"),
        )
        .reset_index()
        .sort_values("hit_rate", ascending=False)
    )
    st.dataframe(by_profile, use_container_width=True, hide_index=True)

    # ìµœê·¼ 90ì¼ ê¸°ì¤€ ìë™ ì¶”ì²œ í”„ë¡œí•„
    recent_90_cut = pd.Timestamp.now() - pd.Timedelta(days=90)
    labeled_90 = label_df[pd.to_datetime(label_df["ts"], errors="coerce") >= recent_90_cut].copy()
    min_auto_samples = st.slider("ìë™ì¶”ì²œ ìµœì†Œ í‘œë³¸ìˆ˜(ë¡œê·¸)", 5, 40, 12, 1)
    if not labeled_90.empty:
        auto_rank = (
            labeled_90.groupby("profile", dropna=False)
            .agg(
                count=("symbol", "count"),
                hit_rate=("hit", lambda s: (s == "HIT").mean() * 100),
                avg_fwd_ret=(f"fwd_{horizon_days}d_ret_pct", "mean"),
            )
            .reset_index()
        )
        auto_rank = auto_rank[auto_rank["count"] >= min_auto_samples]
        if auto_rank.empty:
            st.info("ìë™ì¶”ì²œì— í•„ìš”í•œ í‘œë³¸ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            auto_rank = None
        if auto_rank is not None:
            auto_rank["score"] = auto_rank["hit_rate"] * 0.7 + auto_rank["avg_fwd_ret"] * 0.3
            auto_rank = auto_rank.sort_values(["score", "count"], ascending=False)
            best = auto_rank.iloc[0]
            st.success(
                f"ìµœê·¼ 90ì¼ ìë™ ì¶”ì²œ í”„ë¦¬ì…‹: {best['profile']} "
                f"(HIT {best['hit_rate']:.1f}%, í‰ê·  {best['avg_fwd_ret']:+.2f}%)"
            )
else:
    st.info("ë¼ë²¨ë§ ê°€ëŠ¥í•œ ê¸°ë¡ì´ ì•„ì§ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
